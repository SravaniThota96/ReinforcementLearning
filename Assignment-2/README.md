# Open AI Gym

## Question: Use the Q-learning example given as a basis for your homework and develop a SARSA learning algorithm instead of Q-learning.

* Performed Q-Learner
* Modified same code with few changes according to SARSA functionality \
    i)SARSA uses the Q-value of the actual next action based on current policy instead of maximum Q-value of the next step(Q-Learner)
* Found that SARSA take more episodes initially to reach the end goal. Whereas Q-Learning reach in fewer steps.


